{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fear of the LORD is the beginning of knowledge, but fools despise wisdom and discipline. Proverbs 1:7\n",
    "\n",
    "-------\n",
    "\n",
    "# Welcome to \"AI for All\"\n",
    "\n",
    "Lecture Notes by idebtor@gmail.com, Handong Global University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 2 강 신경망을 내 손으로 만져보기(tf.keras & XOR)\n",
    "\n",
    "---------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## AND 연산 \n",
    "\n",
    "AND 연산은 모두 입력이 참일 때, 참을 결과로 출력하는 연산입니다.  다음의 진리표에 표시된 바와 같습니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/truthtable.png?raw=true\" width=\"600\">\n",
    "<center>그림 1:  OR, AND, NAND, XOR 진리표 </center>\n",
    "\n",
    "\n",
    "이를 넘파이 배열로 나타내면 다음과 같습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], \"float32\") \n",
    "y = np.array([[0], [0], [0], [1]],  \"float32\")\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 가중치와 편향도 정규 분포를 가지는 난수로 초기화 해줍니다. 또한, 학습률은 0.1로 설정하였습니다.  input값이 두개이므로, 가중치도 각각에 맞춰서 두개를 선언해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.86640704  1.44009   ], shape=(2,), dtype=float32)\n",
      "tf.Tensor([-0.23903355], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "w = tf.random.normal([2], 0, 1)  # mean, std\n",
    "b = tf.random.normal([1], 0, 1)  # mean, std\n",
    "eta = 0.1   # learning rate\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 학습을 시켜보겠습니다. 앞에서 만든 편향을 가진 뉴런처럼 코드를 구성하면 됩니다. 각각 네가지 경우를 한번씩 학습할 때마다, 네가지 를 예측한 값과 실제 값의 차이인 error값의 합을 구해서 살펴보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "    return  1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.95151484]\n",
      "100 [-0.16347963]\n",
      "200 [-0.10764188]\n",
      "300 [-0.08082664]\n",
      "400 [-0.0647271]\n",
      "500 [-0.05392516]\n",
      "600 [-0.04616952]\n",
      "700 [-0.04033074]\n",
      "800 [-0.0357811]\n",
      "900 [-0.03213787]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000): \n",
    "    error_sum = 0 \n",
    "    for j in range(4): \n",
    "        y_hat = sigmoid (np.sum(x[j] * w) + b) \n",
    "        error = y[j][0] - y_hat \n",
    "        w = w + eta * 1 * error * x[j]\n",
    "        b = b + eta * 1 * error \n",
    "        error_sum += error \n",
    "    if i % 100 == 0: \n",
    "        print(i, error_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 학습시켜서 나온 가중치와 편향을 사용하여 각각의 케이스를 예측해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [0. 0.] Y: [0.] y_hat: [0.00018573]\n",
      "X: [0. 1.] Y: [0.] y_hat: [0.04839294]\n",
      "X: [1. 0.] Y: [0.] y_hat: [0.04866675]\n",
      "X: [1. 1.] Y: [1.] y_hat: [0.9333522]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'y_hat:', sigmoid(np.sum(x[i]*w) + b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이, 실제로 1이 나와야하는 값은 1에 가깝게, 0에 가까워야하는 값은 0에 가깝게 예측이 되었습니다. `[0 0]` 케이스의 경우에는 다른 케이스들 보다 더 0에 가까운걸로 보아 더 확실한 케이스라는 점을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR 연산\n",
    "\n",
    "OR 연산은 입력들 중에 하나라도 참이면, 참을 결과로 출력하는 연산입니다.  이를 넘파이 배열로 나타내면 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], \"float32\") \n",
    "y = np.array([[0], [1], [1], [1]],  \"float32\")\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 AND와 같은 가중치, 편향, 학습률 및 학습 모델로 학습을 시키면 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.9447308]\n",
      "100 [0.07116947]\n",
      "200 [0.02488196]\n",
      "300 [0.01035471]\n",
      "400 [0.00376951]\n",
      "500 [0.00040788]\n",
      "600 [-0.00139235]\n",
      "700 [-0.00237067]\n",
      "800 [-0.00289633]\n",
      "900 [-0.00316517]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000): \n",
    "    error_sum = 0 \n",
    "    for j in range(4): \n",
    "        y_hat = sigmoid (np.sum(x[j] * w) + b) \n",
    "        error = y[j][0] - y_hat \n",
    "        w = w + eta * 1 * error * x[j]\n",
    "        b = b + eta * 1 * error \n",
    "        error_sum += error \n",
    "    if i % 100 == 0: \n",
    "        print(i, error_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행할 수록 error값의 합이 0에 가까워지는것을 확인할 수 있습니다. 각각의 케이스들을 해당 가중치와 편향으로 예측해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [0. 0.] Y: [0.] y_hat: [0.01864035]\n",
      "X: [0. 1.] Y: [1.] y_hat: [0.99235314]\n",
      "X: [1. 0.] Y: [1.] y_hat: [0.99231553]\n",
      "X: [1. 1.] Y: [1.] y_hat: [0.9999988]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'y_hat:', sigmoid(np.sum(x[i]*w) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR 연산\n",
    "XOR은 AND나 OR연산과는 다르게 홀수 개의 입력이 참일 때, 결과가 참이 됩니다. 입력을 두개라고 한다면, 위의 진리표에 나타난 바와 같습니다.\n",
    "\n",
    "이를 넘파이 배열로 나타내면 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]],  \"float32\") \n",
    "y = np.array([[0], [1], [1], [0]],  \"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 AND와 같은 가중치, 편향, 학습률 및 학습 모델로 학습을 시키면 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.00328542]\n",
      "100 [-0.00331896]\n",
      "200 [-0.00330157]\n",
      "300 [-0.00325537]\n",
      "400 [-0.00319251]\n",
      "500 [-0.00312098]\n",
      "600 [-0.00304543]\n",
      "700 [-0.00296872]\n",
      "800 [-0.00289285]\n",
      "900 [-0.00281856]\n",
      "1000 [-0.00274621]\n",
      "1100 [-0.00267683]\n",
      "1200 [-0.00261005]\n",
      "1300 [-0.0025459]\n",
      "1400 [-0.0024845]\n",
      "1500 [-0.00242584]\n",
      "1600 [-0.00236955]\n",
      "1700 [-0.00231564]\n",
      "1800 [-0.00226396]\n",
      "1900 [-0.00221459]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000): \n",
    "    error_sum = 0 \n",
    "    for j in range(4): \n",
    "        y_hat = sigmoid (np.sum(x[j] * w) + b) \n",
    "        error = y[j][0] - y_hat \n",
    "        w = w + eta * 1 * error * x[j]\n",
    "        b = b + eta * 1 * error \n",
    "        error_sum += error \n",
    "    if i % 100 == 0: \n",
    "        print(i, error_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이, 특정 학습 지점부터 에러 값이 0이 나와 버리고 있습니다. 이것이 과연 학습이 잘된걸까요? 계산된 가중치와 편향을 가지고 각 케이스를 계산해보았습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [0. 0.] Y: [0.] y_hat: [0.01864035]\n",
      "X: [0. 1.] Y: [1.] y_hat: [0.99235314]\n",
      "X: [1. 0.] Y: [1.] y_hat: [0.99231553]\n",
      "X: [1. 1.] Y: [1.] y_hat: [0.9999988]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'y_hat:', sigmoid(np.sum(x[i]*w) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이, 결과가 0이 나와야하든지, 1이 나와야하든지, 모든 케이스가 0.5에 가깝게 나오고 있습니다. 이것은 원하던 결과가 아닙니다. 결과를 해석해보자면, 가중치와 편향 값은 모두 케이스 순서에 의존적이 된다는 것을 알 수 있습니다. 먼저 들어간 `[1 1]`이라는 케이스가 네번째에 들어가는 `[0 0]`이라는 케이스보다 영향을 준다는 것입니다. `[1 1]`이라는 케이스가 먼저 들어가서 가중치와 편향에 중대한 영향을 미치고 이 값들을 가지고 학습을 진행한다는 것이 문제입니다.\n",
    "\n",
    "그러면 XOR문제는 풀지 못하는 걸까요? 여러 층의 퍼셉트론을 사용하면 해결이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단층 퍼셉트론에서의 XOR 문제점\n",
    "\n",
    "인공 신경망에서는 단층 퍼셉트론으로 XOR 연산이 불가능하다는 것은 마빈 민스키 등에 의해서 밝혀졌습니다. 이러한 내용이 밝혀지면서 인공지능의 겨울이 찾아왔었습니다. 그야말로 전설같은 이야기로 잘 알려져 있습니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-history.jpg?raw=true\" width=\"900\">\n",
    "<center>그림 2: XOR 문제와 인공 지능의 발전사</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공 신경망(ANN, Aritificial Neural Networks)은 1943년 신경생리학자 Warren McCulloch과 수학자 Walter Pitts가 'A Logical Calculus of Ideas Immanent In Nervous Activity' 처음 소개했습니다. 그 이후 1960년대까지 당싱에 등장한 인공 신경망을 통해 사람들은 지능을 가지 기계가 상당히 엄청난 일을 해낼 것이라 생각했습니다. 그러나, 위의 그림(출처: [beamandrew's blog](https://beamandrew.github.io/deeplearning/2017/02/23/deep_learning_101_part1.html))처럼 사람들의 기대와는 달리 인공 신경망으로 XOR문제를 해결할 수 없게 되었고, 인공 지능과 관련한 연구는 암흑기로 접어 들게 되었다. 그래도, 1990년 대에는 SVM과 성능이 좋은 다른 머신러닝 알고리즘들이 나올 정도도 꾸준한 연구가 진행은 되고 있었습니다. \n",
    "\n",
    "2000년대에 들어서면서 인공 신경망은 2012년 ILSVRC2012 대회에서 인공 신경망을 깊게 쌓은 딥러닝 모델인 AlexNet이 압도적인 성적으로 우승하면서 다시금 주목받게 되었습니다. 이렇게 인공 신경망에 기반을 둔 딥러닝이 다시 주목받게 된 계기가 되었습니다. \n",
    "\n",
    "인공 지능의 발전사에서 약간의 의미가 있었던 XOR 문제를 이제 어렵지 않게 풀어볼 수 있는 문제가 되었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR 연산 다층 신경망\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/ai4all-xor.png?raw=true\" width=\"600\">\n",
    "<center>그림 2:  XOR 연산을 위한 다층 인공 신경망</center>\n",
    "\n",
    "XOR 연산을 위한 2단의 Dense Layer로 구성하였습니다. Dense는 기본적인 레이어로, 입력과 출력 사이에 있는 모든 뉴런이 서로 연결되어 있는 레이어입니다. Dense Layer는 아래와 같이 선언이 가능합니다.\n",
    "\n",
    "```\n",
    "tf.keras.layers.Dense()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 Layer는 순차적으로 배치되어있습니다. 이를 Sequential 신경망이라고 합니다. 이것은 아래와 같이 선언합니다.\n",
    "```\n",
    "tf.keras.Sequential()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential한 Dense Layer를 2층으로 쌓도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "model = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(2,)), \n",
    "    tf.keras.layers.Dense(8, activation='sigmoid'), \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순차적인 신경망안에 두개의 Dense Layer를 배치하고, 첫번째 Dense Layer는 2개의 뉴런을 선언하였고, 각 뉴런은 sigmoid를 활성함수로 가집니다. 입력 값은 두개이므로 모양이 (2,) 모양입니다. 두번째 Dense Layer는 1개의 뉴런을 선언하고, 마찬가지로 sigmoid 활성함수를 사용하였습니다.\n",
    "\n",
    "XOR연산이므로, x와 y값은 그대로 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]],  \"float32\") \n",
    "y = np.array([[0], [1], [1], [0]],  \"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제는 model을 준비시키는 명령어를 사용하여 최적화 함수(optimizer)와 손실 함수(loss)를 정의합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), # 'adam', 'sgd', ...\n",
    "    loss='mse',   # 'mean_squared_error' 'binary_crossentropy'\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras에서는 다양한 최적화 함수와 손실 함수를 제공합니다. 그 중에서도 SGD(Stochastic Gradient Descent)는 확률적 경사 하강법이라고 합니다. 경사 하강법은 앞선 포스팅에서 설명하였고, 이 경사 하강법을 한번에 계산(전체 데이터세트를 사용)하지 않고 확률을 이용하여 부분적으로 나눠서 계산을 한다는 의미입니다.\n",
    "\n",
    "SGD(Stochastic Gradient Descent)\n",
    "\n",
    "- 기존의 경사 하강법은 데이터세트의 크기가 너무 커지면 계산이 오래 걸리는 단점이 있었습니다.\n",
    "- SGD는 반복당 하나의 데이터(Batch=1)만을 사용하여 적은 계산으로 기울기를 얻어내는 방식입니다.\n",
    "- 단점: 반복이 충분하면 효과는 좋지만, 노이즈가 심합니다. 최저점을 찾는다는 보장이 없습니다. 가능성만 높을 뿐입니다.\n",
    "- 위의 단점을 극복하기 위해서 미니 배치 SGD가 있습니다. 배치를 너무 크게도 너무 작게도 잡지 않고 SGD보다 노이즈는 적게, 일반 경사 하강법보다는 효율적으로 찾는 방식입니다. \n",
    "\n",
    "손실 함수(Loss Function)은 RMSE의 제곱인 MSE를 사용하기로 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이, summary() 메소드를 사용하여 형성된 신경망의 구조를 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 257\n",
      "Trainable params: 257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터는 첫번째 Layer에서 입력값에 가중치가 곱해지고 편향이 더해져서 은닉층의 각 노드에 3개의 파라미터가 전달되어 총 6개입니다. 두번째 Layer에서는 첫 Layer에서 나온 출력 값 두개와 편향을 합쳐서 총 3개의 값이 두번째 층에 전달되어 결과적으로 하나의 출력(예측) 값이 나오게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x, y, epochs=20000, batch_size=1, verbose = 0)\n",
    "#print(model.evaluate(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행하면 위와 같은 출력이 나오며, 손실 값을 알려줍니다. 손실 값은 학습을 진행할수록 0에 가까워지는 것을 확인할 수 있습니다.\n",
    "\n",
    "이제 제대로 학습이 되었는지 확인해봅니다. 아래의 코드를 통해서 x에 대한 예측 값을 출력 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5258435]\n",
      " [0.5258435]\n",
      " [0.5258435]\n",
      " [0.5258435]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(x))\n",
    "# print(model.predict_classes(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답은 0, 1, 1, 0 순서입니다. 각각 0과 1에 해당하는 수에 가깝게 나오고 있는것을 확인 할 수 있습니다. 이는 학습을 더 많이 할수록 더 정답에 해당하는 수치로 갈것 입니다.\n",
    "\n",
    "이제는 가중치와 편향 값을 확인해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'dense_9/kernel:0' shape=(2, 16) dtype=float32, numpy=\n",
      "array([[-1.8383033 ,  2.002077  , -0.15336403,  0.17284101,  0.40487793,\n",
      "        -0.39525723,  0.894477  ,  0.19128728, -0.963422  ,  0.661773  ,\n",
      "         0.21490027, -0.12429199,  0.32307467, -0.32486495,  0.4248714 ,\n",
      "         0.35300758],\n",
      "       [ 1.8383809 , -2.0019991 ,  0.027582  ,  0.4018159 ,  0.36233777,\n",
      "         0.04373157, -0.89447284,  0.1680474 ,  0.96346265, -0.07535206,\n",
      "         0.18341437,  0.0245843 , -0.323068  ,  0.25839257, -0.13547379,\n",
      "         0.35302055]], dtype=float32)>\n",
      "<tf.Variable 'dense_9/bias:0' shape=(16,) dtype=float32, numpy=\n",
      "array([-1.06409745e-04, -3.34489450e-05, -2.87178047e-02, -1.75003061e-06,\n",
      "       -3.62346560e-01, -4.74123955e-02, -1.76793710e-05,  1.11435475e-06,\n",
      "       -3.74453484e-05,  4.57547575e-01, -7.41923986e-06, -2.46842932e-02,\n",
      "       -2.57454326e-06, -5.60296621e-06,  5.21387041e-01, -3.53024423e-01],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'dense_10/kernel:0' shape=(16, 8) dtype=float32, numpy=\n",
      "array([[ 0.7058575 , -0.9632141 ,  0.72024685, -1.6391068 ,  0.14220835,\n",
      "        -0.5173822 ,  1.0931907 ,  1.0669917 ],\n",
      "       [ 0.1258447 , -0.8050199 ,  0.890411  , -1.6292588 , -0.06278258,\n",
      "        -1.1615973 ,  1.0238702 ,  1.3305454 ],\n",
      "       [ 0.48837632, -0.00574703, -0.32741088,  0.42822203,  0.11559074,\n",
      "        -0.1957597 , -0.14594874, -0.2758522 ],\n",
      "       [-0.39779344, -0.09886017,  0.41206768, -0.14604221,  0.2541984 ,\n",
      "        -0.21198432, -0.2393871 ,  0.1329013 ],\n",
      "       [-0.5134334 ,  0.15216905, -0.24365158,  0.66687316,  0.28657573,\n",
      "        -0.2684437 ,  0.3699968 , -0.48526666],\n",
      "       [-0.49117747,  0.32018355, -0.49373874,  0.48590025,  0.10513802,\n",
      "         0.34467605,  0.14656852, -0.45017564],\n",
      "       [ 0.334067  , -0.4858078 ,  0.80374026, -0.76785076,  0.3511925 ,\n",
      "        -0.5640605 ,  0.3638718 ,  0.2917795 ],\n",
      "       [-0.10991909, -0.30191717,  0.15956807, -0.03522239,  0.29942983,\n",
      "        -0.34222916,  0.2849412 , -0.43978345],\n",
      "       [ 0.6688643 , -0.6036436 ,  0.43786433, -0.4569154 ,  0.06097913,\n",
      "        -0.4175958 ,  0.41245958,  0.78461045],\n",
      "       [ 0.3123663 ,  0.19668241, -0.4936781 ,  0.39523473,  0.27708873,\n",
      "         0.32457882, -0.32284808,  0.12715723],\n",
      "       [ 0.29659042, -0.33638403,  0.3991199 ,  0.00970245,  0.06696312,\n",
      "        -0.39452824, -0.2534092 , -0.3309946 ],\n",
      "       [-0.32970318,  0.15869124,  0.12347951,  0.0636956 ,  0.46742722,\n",
      "         0.1388264 , -0.10197168,  0.46886715],\n",
      "       [-0.13752337, -0.20189661, -0.08663943, -0.01893372, -0.20724799,\n",
      "         0.003289  ,  0.2933333 ,  0.6289494 ],\n",
      "       [ 0.42960775,  0.11195946,  0.40844974,  0.02848015,  0.41389018,\n",
      "         0.01599147,  0.49293357, -0.04009173],\n",
      "       [ 0.44137707,  0.17214079, -0.04748738,  0.27793783, -0.15259843,\n",
      "         0.26831523, -0.4565593 , -0.582044  ],\n",
      "       [-0.50168216,  0.12582068, -0.03975227, -0.04790363,  0.22198993,\n",
      "         0.16114268, -0.28354645, -0.61650956]], dtype=float32)>\n",
      "<tf.Variable 'dense_10/bias:0' shape=(8,) dtype=float32, numpy=\n",
      "array([-0.17324542,  0.38526043, -0.35156494,  0.89018744,  0.05550064,\n",
      "        0.37838584, -0.286459  , -0.49181077], dtype=float32)>\n",
      "<tf.Variable 'dense_11/kernel:0' shape=(8, 1) dtype=float32, numpy=\n",
      "array([[ 0.8045657 ],\n",
      "       [-1.7808132 ],\n",
      "       [ 1.521841  ],\n",
      "       [-3.220851  ],\n",
      "       [-0.21634585],\n",
      "       [-1.7647241 ],\n",
      "       [ 1.659328  ],\n",
      "       [ 2.19481   ]], dtype=float32)>\n",
      "<tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([-0.6381905], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "for weight in model.weights: \n",
    "    print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Model Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking the model.\n",
    "- increasing the number of hidden layers or nodes \n",
    "- trying to use different activation functions or optimizer\n",
    "- using different batch sizes, 1 or 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(2,)), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(2,)), \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Is it possible to solve XOR with no activation function at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    '''\n",
    "    The function returns the variable that is passed in, so all types work.\n",
    "    '''\n",
    "    return x\n",
    "\n",
    "model = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Dense(32, activation='linear', input_shape=(2,)), \n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    '''\n",
    "    The function returns the variable that is passed in, so all types work.\n",
    "    '''\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "__Be joyful always!__ 1 Thes.5:16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
