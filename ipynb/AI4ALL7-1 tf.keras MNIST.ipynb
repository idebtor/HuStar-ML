{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fear of the LORD is the beginning of knowledge, but fools despise wisdom and discipline. Proverbs 1:7\n",
    "\n",
    "-------\n",
    "\n",
    "# Welcome to \"AI for All\"\n",
    "\n",
    "Lecture Notes by idebtor@gmail.com, Handong Global University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제 1 강 신경망을 내 손으로 만져보기(tf.keras & MNIST)\n",
    "\n",
    "---------\n",
    "\n",
    "\n",
    "## Greetings!\n",
    "인공지능이나 기계학습을 이해하려면, 참 여러 가지를 알아야 합니다. 특히 수학적 개념과 프로그래밍(코딩)과 친숙해져야 합니다. 수학적 개념에서는 텐서, 미분, 경사 하강법, 행렬 연산 등등이고, 코딩도 익숙하면 익숙할수록 좋습니다. 그러나, 우리의 목적은 이 모든 것을 다 알아야 한다는 것이 아니라 수학적으로 너무 깊이 들어가지 않고, 이러한 개념들을 이해하여 결국 인공지능의 원리를 이해하는데 있습니다. 특히 수학이나 코딩을 어려워 할 수 있으므로, 수학 기호는 가능한 사용하지 않으려 합니다. \n",
    "\n",
    "처음에는 여러 분이 잘 알아들을 수 없는 실제 신경망 예제로 시작하면서, 그 개념을 전체적으로 몇개 소개합니다. 그 이후에 이같은 예제를 이해하기 위해서 꼭 필요한 개념들을 좀 더 자세히 깊이 있게 설명할 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MNIST 데이터셋의 개요\n",
    "\n",
    "인공지능을 개발할 때 사용할 수 있는 여러 가지 개발 딥 러닝 프레임워크(Deep Learning Framework)들이 있습니다.  현재 가장 많이 사용되고 있는 프레임워크는 두 가지로 압축할 수 있으며 모두 open source platform이며, 파이썬을 가장 기본적인 front-end로 지원합니다.  \n",
    "\n",
    "- Tensorflow(2.x) & tf.keras: 구글에서 제공함\n",
    "- PyTorch: 페이스북에서 제공함\n",
    "\n",
    "여기서는 텐서플로와 케라스로 가장 기본적이고 \"Hello World\"에 해당하는 MNIST 데이터셋을 다루는 것부터 시작하도록 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "여러분은 컴퓨터 프로그래밍을 처음 배울 때를 어떤 프로그램을 제일 먼저 작성했는지 기억이 나는지요? 누구든지 어떤 프로그래밍 언어를 처음 접할 때 시도해보는 것은 \"Hello World!\"를 출력하는 프로그램을 작성해보는 것입니다.  일종의 전통이죠. \"Hello World! 프로그램을 500개도 넘게 모아 둔 [웹사이트](http://helloworldcollection.de/)도 있더군요. 기계학습에 비슷한 전통이 생기는 것 같습니다.  기계학습을 처음 배울 때, 누구나 한번은 시도해보는 것이 바로 MNIST(엠니스트) 데이터셋을 다루는 일입니다. \n",
    "\n",
    "[MNIST(National Institute of Standards and Technology)자료](http://yann.lecun.com/exdb/mnist/)는 다음과 같이 손으로 쓴 숫자들의 이미지를 압축하여 한 파일에 모아둔 것입니다. 또한 각 숫자가 어떤 숫자인지 알려주는 각 (클래스)레이블 파일이 있습니다. \n",
    "\n",
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/MNIST50419.png?raw=true\" width=\"600\">\n",
    "<center>그림 1: MNIST 데이터셋의 첫 5장의 이미지</center>\n",
    "\n",
    "이번 강의에서는 이러한 MNIST 데이터셋으로 신경망 모델을 훈련하고, 새로운 데이터셋으로 신경망 모델을 테스트해볼 것입니다. 우리의 목적은 최고의 성능을 자랑한는 신경망 모델을 만드는 것이 아니라 인위적인 자료가 아니라 범용으로 사용되는 실전 자료로 신경망을 모델링하는데 목적이 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터셋 시각화\n",
    "\n",
    "다음 코드는 MNIST 데이터셋의 이미지들을 추출하여 시각화합니다. 한 줄에 최대 10장씩 100까지 시각화하고, 각 이미지 아래에 레이블(실제 값)을 표시합니다. 때때로 사람이 인식하기에도 명확하지 않은 이미지가 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code displays upto 100 images\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test)= mnist.load_data()\n",
    "\n",
    "images = x_train[:5]\n",
    "labels = y_train[:5]\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(10, 10, i + 1)     # display images upto 100\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[i], cmap=\"gray\")\n",
    "    plt.xlabel(labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 학습 자료 준비 하기(전처리 과정)\n",
    "\n",
    "텐서플로를 주피터 노트북 내에서 사용하려면, 텐서플로 라이브러리를 import해야 합니다. \n",
    "- tensorflow을 import하면, __tensorflow__라는 긴 이름을 대신 짧은 이름 __tf__를 사용할 수 있도록 다음과 같이 import하고, version도 체크할 수 있습니다. tensorflow는 2.x 버전을 사용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손글씨 숫자 이미지들로 구성된 데이터셋을 가져와서 한 세트는 학습의 목적으로, 한 세트는 테스트를 위하여 각각의 변수들에 저장합니다. \n",
    "\n",
    "- 학습을 목적으로 저장하는 데이터 셋은 train이란 이름으로 저장되고, 테스트(검증)을 위한 데이터셋은 test란 이름으로 저장합니다. \n",
    "- x는 손글씨 숫자로 된 이미지 자료이며, y는 이미지가 의미하는 실제 숫자입니다. 이런 실제 숫자의 값을 label 혹은 target 이라 부르기도 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 과정에 사용할 train 자료의 개수는 60000개 이고, 테스트 자료의 개수는 10000개입니다. 각 자료(sample)의 x는 가로x세로가 각각 28x28 픽셀로 구성된 grayscale 이미지이며, y는 각 이미지의 실제 값(label)을 가지고 있습니다. 다음 그림은 데이터의 상태를 잘 보여주고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/MNISTdataset2.png?raw=true\" width=\"600\">\n",
    "<center>그림 2: MNIST 데이터셋의 x_train 과 y_train 훈련 자료 형상</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬을 사용하여 그의 크기와 형상(shape)을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))         # 6만개 label or target \n",
    "print(y_train)              # 6만개를 다 프린트하기 보다는 앞과 뒤의 몇개만 보여줍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1.\n",
    "\n",
    "x_train가 가지고 있는 6만개의 이미지 자료들 중에 첫 한 개를 출력해봅니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: \n",
    "\n",
    "우리는 출력한 첫 데이타는 28 x 28 배열의 2D 텐서인 것을 알고 있습니다. 2D 텐서를 출력할 때, 디폴트 print를 사용하지 말고, 한 줄에 한 row씩, 28 x 28 형식으로 출력하도록 다음과 같이 코딩을 해봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0 \n",
      "  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n"
     ]
    }
   ],
   "source": [
    "for row in x_train[0]:                    # row \n",
    "    for pix in row:                    # each element in a row\n",
    "        print('%3d' % pix, end=' ')    # print('{0:3d}'.format(j), end=' ') \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 숫자는 이미지 픽셀이며, 각 픽셀은 0~255사이의 값이며, 각 픽셀의 밝기 정도를 나타냅니다. 가장 작은 수 0이면 가장 어두운 검은색이며, 255는 가장 밝은 색, 흰색을 나타냅니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: \n",
    "이제 이런 데이터의 값을 실제로 그림으로 나타내면 더 좋지 않을까요? 다행히도, 이러한 단순한 배열을 실제 이미지로 시각화할 수 있는 파이썬 표준 라이브러리인 맷플롯립(matplotlib)이 있습니다. 이 라이브러리을 import하고, imshow() 함수를 이용하여 시각화할 수 있습니다. 모든 이미지가 x_train에 저장되어 있으므로, 그 중에 첫 번째 이미지는 `x_train[0]`으로 슬라이싱하면 됩니다. 그러면, 첫 번째 이미지를 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN80lEQVR4nO3df6hcdXrH8c+ncf3DrBpTMYasNhuRWBWbLRqLSl2RrD9QNOqWDVgsBrN/GHChhEr6xyolEuqP0qAsuYu6sWyzLqgYZVkVo6ZFCF5j1JjU1YrdjV6SSozG+KtJnv5xT+Su3vnOzcyZOZP7vF9wmZnzzJnzcLife87Md879OiIEYPL7k6YbANAfhB1IgrADSRB2IAnCDiRxRD83ZpuP/oEeiwiPt7yrI7vtS22/aftt27d281oAesudjrPbniLpd5IWSNou6SVJiyJia2EdjuxAj/XiyD5f0tsR8U5EfCnpV5Ku6uL1APRQN2GfJekPYx5vr5b9EdtLbA/bHu5iWwC61M0HdOOdKnzjND0ihiQNSZzGA03q5si+XdJJYx5/R9L73bUDoFe6CftLkk61/V3bR0r6kaR19bQFoG4dn8ZHxD7bSyU9JWmKpAci4o3aOgNQq46H3jraGO/ZgZ7ryZdqABw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii4ymbcXiYMmVKsX7sscf2dPtLly5tWTvqqKOK686dO7dYv/nmm4v1u+66q2Vt0aJFxXU///zzYn3lypXF+u23316sN6GrsNt+V9IeSfsl7YuIs+toCkD96jiyXxQRH9TwOgB6iPfsQBLdhj0kPW37ZdtLxnuC7SW2h20Pd7ktAF3o9jT+/Ih43/YJkp6x/V8RsWHsEyJiSNKQJNmOLrcHoENdHdkj4v3qdqekxyTNr6MpAPXrOOy2p9o++uB9ST+QtKWuxgDUq5vT+BmSHrN98HX+PSJ+W0tXk8zJJ59crB955JHF+nnnnVesX3DBBS1r06ZNK6577bXXFutN2r59e7G+atWqYn3hwoUta3v27Cmu++qrrxbrL7zwQrE+iDoOe0S8I+kvauwFQA8x9AYkQdiBJAg7kARhB5Ig7EASjujfl9om6zfo5s2bV6yvX7++WO/1ZaaD6sCBA8X6jTfeWKx/8sknHW97ZGSkWP/www+L9TfffLPjbfdaRHi85RzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlrMH369GJ948aNxfqcOXPqbKdW7XrfvXt3sX7RRRe1rH355ZfFdbN+/6BbjLMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJM2VyDXbt2FevLli0r1q+44opi/ZVXXinW2/1L5ZLNmzcX6wsWLCjW9+7dW6yfccYZLWu33HJLcV3UiyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB9ewD4JhjjinW200vvHr16pa1xYsXF9e9/vrri/W1a9cW6xg8HV/PbvsB2zttbxmzbLrtZ2y/Vd0eV2ezAOo3kdP4X0i69GvLbpX0bEScKunZ6jGAAdY27BGxQdLXvw96laQ11f01kq6uuS8ANev0u/EzImJEkiJixPYJrZ5oe4mkJR1uB0BNen4hTEQMSRqS+IAOaFKnQ287bM+UpOp2Z30tAeiFTsO+TtIN1f0bJD1eTzsAeqXtabzttZK+L+l429sl/VTSSkm/tr1Y0u8l/bCXTU52H3/8cVfrf/TRRx2ve9NNNxXrDz/8cLHebo51DI62YY+IRS1KF9fcC4Ae4uuyQBKEHUiCsANJEHYgCcIOJMElrpPA1KlTW9aeeOKJ4roXXnhhsX7ZZZcV608//XSxjv5jymYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9knulFNOKdY3bdpUrO/evbtYf+6554r14eHhlrX77ruvuG4/fzcnE8bZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmTW7hwYbH+4IMPFutHH310x9tevnx5sf7QQw8V6yMjIx1vezJjnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUVnnnlmsX7PPfcU6xdf3Plkv6tXry7WV6xYUay/9957HW/7cNbxOLvtB2zvtL1lzLLbbL9ne3P1c3mdzQKo30RO438h6dJxlv9LRMyrfn5Tb1sA6tY27BGxQdKuPvQCoIe6+YBuqe3XqtP841o9yfYS28O2W/8zMgA912nYfybpFEnzJI1IurvVEyNiKCLOjoizO9wWgBp0FPaI2BER+yPigKSfS5pfb1sA6tZR2G3PHPNwoaQtrZ4LYDC0HWe3vVbS9yUdL2mHpJ9Wj+dJCknvSvpxRLS9uJhx9sln2rRpxfqVV17ZstbuWnl73OHir6xfv75YX7BgQbE+WbUaZz9iAisuGmfx/V13BKCv+LoskARhB5Ig7EAShB1IgrADSXCJKxrzxRdfFOtHHFEeLNq3b1+xfskll7SsPf/888V1D2f8K2kgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLtVW/I7ayzzirWr7vuumL9nHPOaVlrN47eztatW4v1DRs2dPX6kw1HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2SW7u3LnF+tKlS4v1a665plg/8cQTD7mnidq/f3+xPjJS/u/lBw4cqLOdwx5HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2w0C7sexFi8abaHdUu3H02bNnd9JSLYaHh4v1FStWFOvr1q2rs51Jr+2R3fZJtp+zvc32G7ZvqZZPt/2M7beq2+N63y6ATk3kNH6fpL+PiD+X9FeSbrZ9uqRbJT0bEadKerZ6DGBAtQ17RIxExKbq/h5J2yTNknSVpDXV09ZIurpXTQLo3iG9Z7c9W9L3JG2UNCMiRqTRPwi2T2ixzhJJS7prE0C3Jhx229+W9Iikn0TEx/a4c8d9Q0QMSRqqXoOJHYGGTGjozfa3NBr0X0bEo9XiHbZnVvWZknb2pkUAdWh7ZPfoIfx+Sdsi4p4xpXWSbpC0srp9vCcdTgIzZswo1k8//fRi/d577y3WTzvttEPuqS4bN24s1u+8886WtccfL//KcIlqvSZyGn++pL+V9LrtzdWy5RoN+a9tL5b0e0k/7E2LAOrQNuwR8Z+SWr1Bv7jedgD0Cl+XBZIg7EAShB1IgrADSRB2IAkucZ2g6dOnt6ytXr26uO68efOK9Tlz5nTUUx1efPHFYv3uu+8u1p966qli/bPPPjvkntAbHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+znnntusb5s2bJiff78+S1rs2bN6qinunz66acta6tWrSque8cddxTre/fu7agnDB6O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpx9oULF3ZV78bWrVuL9SeffLJY37dvX7FeuuZ89+7dxXWRB0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEVF+gn2SpIcknSjpgKShiPhX27dJuknS/1ZPXR4Rv2nzWuWNAehaRIw76/JEwj5T0syI2GT7aEkvS7pa0t9I+iQi7ppoE4Qd6L1WYZ/I/Owjkkaq+3tsb5PU7L9mAXDIDuk9u+3Zkr4naWO1aKnt12w/YPu4FusssT1se7irTgF0pe1p/FdPtL8t6QVJKyLiUdszJH0gKST9k0ZP9W9s8xqcxgM91vF7dkmy/S1JT0p6KiLuGac+W9KTEXFmm9ch7ECPtQp729N425Z0v6RtY4NefXB30EJJW7ptEkDvTOTT+Ask/Yek1zU69CZJyyUtkjRPo6fx70r6cfVhXum1OLIDPdbVaXxdCDvQex2fxgOYHAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HvK5g8k/c+Yx8dXywbRoPY2qH1J9NapOnv7s1aFvl7P/o2N28MRcXZjDRQMam+D2pdEb53qV2+cxgNJEHYgiabDPtTw9ksGtbdB7Uuit071pbdG37MD6J+mj+wA+oSwA0k0Enbbl9p+0/bbtm9toodWbL9r+3Xbm5uen66aQ2+n7S1jlk23/Yztt6rbcefYa6i322y/V+27zbYvb6i3k2w/Z3ub7Tds31Itb3TfFfrqy37r+3t221Mk/U7SAknbJb0kaVFEbO1rIy3YflfS2RHR+BcwbP+1pE8kPXRwai3b/yxpV0SsrP5QHhcR/zAgvd2mQ5zGu0e9tZpm/O/U4L6rc/rzTjRxZJ8v6e2IeCcivpT0K0lXNdDHwIuIDZJ2fW3xVZLWVPfXaPSXpe9a9DYQImIkIjZV9/dIOjjNeKP7rtBXXzQR9lmS/jDm8XYN1nzvIelp2y/bXtJ0M+OYcXCarer2hIb7+bq203j309emGR+YfdfJ9OfdaiLs401NM0jjf+dHxF9KukzSzdXpKibmZ5JO0egcgCOS7m6ymWqa8Uck/SQiPm6yl7HG6asv+62JsG+XdNKYx9+R9H4DfYwrIt6vbndKekyjbzsGyY6DM+hWtzsb7ucrEbEjIvZHxAFJP1eD+66aZvwRSb+MiEerxY3vu/H66td+ayLsL0k61fZ3bR8p6UeS1jXQxzfYnlp9cCLbUyX9QIM3FfU6STdU92+Q9HiDvfyRQZnGu9U042p43zU+/XlE9P1H0uUa/UT+vyX9YxM9tOhrjqRXq583mu5N0lqNntb9n0bPiBZL+lNJz0p6q7qdPkC9/ZtGp/Z+TaPBmtlQbxdo9K3ha5I2Vz+XN73vCn31Zb/xdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D+f1mbtgJ8kQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0], cmap='gray')    # use 'Greys' or cmap=plot.cm.binary for inverted grayscale image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 이미지를 컴퓨터는 어떻게 인식할까요? \n",
    "\n",
    "이 이미지는 가로 28 x 세로 28 = 총 784개로의 픽셀(pixel)로 이루어져 있습니다. 즉 이미지는 0~255까지 숫자 중의 하나로 채워진 긴 행렬로 이루어진 수의 집합으로 변환되어 컴퓨터(신경망 모델)에 입력됩니다. \n",
    "\n",
    "이와 같은 이미지를 여러 장, 여러 번 입력하여 신경망 모델을 학습하고자 하는 것이 목적이며, 학습하는 과정에서는 모델에게 각 이미지의 값이 무엇이라는 것을 알려주어야 합니다. 즉 위와 같은 이미지의 값이 5라는 것을 알려 줄 값이 저장되어 있는 변수가 y이며, 이를 label(레이블), 실제값고, 목표값(target value, or class)이라고도 부릅니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4: label (or target) 확인하기\n",
    "\n",
    "각 이미지의 레이블(label or target)값을 다음의 코드로 확인할 수 있습니다.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])         # 첫번째 이미지의 label\n",
    "print(y_train)            # 6만개를 다 프린트하기 보다는 앞과 뒤의 몇개만 보여줍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 같은 종류의 데이터인데 굳이 훈련 데이터셋과 테스트 데이터 셋으로 구별해 놓은 것은 모델을 학습할 때에는 훈련 데이터셋을 사용하기 위한 것입니다. \n",
    "- 손글씨 숫자를 분별해내는 기계학습 모델을 완성한 후, 이 모델의 예측 정확도를 평가할 때는 테스트 데이터셋을 사용하기 위함입니다. \n",
    "- 만약, 모델의 학습 과정과 정확도 평가에 동일한 데이터셋을 사용하면, 모델의 학습과정에 사용된 데이터에만 예측이 잘 되는 오버피팅(overfitting)이 발생할 수 있습니다. \n",
    "\n",
    "- x_train의 이미지들이 모델의 입력으로 들어가서 y_train 실제 값(레이블)이 나오도록 모델을 반복적으로 학습시켜야 합니다. \n",
    "- 학습의 결과로 모델의 각종 파라미터들이 다 정해지면, 그 모델에 x_test의 이미지들을 입력해서 얼마나 정확한 y_test값을 예측하는지 평가해보는 것입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 5: 데이터의 정규화 (Normalization)\n",
    "\n",
    "손글씨 숫자 이미지 데이터는 0~255 사이의 값을 가집니다. 이 자료들을 모델의 학습 데이터로 사용하기 전에 0 ~ 1 사이의 범위를 갖도록 변경하여 모델에 입력할 때, 더 잘 작동을 합니다. 이렇게 데이터의 폭이 클 때, 적절한 값으로 분산의 정도를 바꾸는 과정을 __데이터 정규화(normalization)__라고 합니다.  정수형의 값을 255로 나누는 것이 아니라 255.0 실수형(float type)으로 나누면, 결과는 실수형으로 산출이 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train/255.0, x_test/255.0     # 0~255 이미지 값을 0 ~ 1로 정규화하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 신경망 모델 설정하기\n",
    "\n",
    "신경망의 핵심 구성 요소들은 노드(node or neuron)와 층(layer)입니다. 여러 층들이 하나의 신경망을 구성하며, 각 층은 노드로 구성되어 있습니다. 싱경망은 입력층과 출력층, 그 두 층 사이에 한 개 혹은 여러 개의 은닉층으로 구성되어 있습니다. 다음은 여기서 사용할 가장 간단한 하나의 은닉층만 있는 3층 신경망입니다. 각 층은 여러 개의 노드로 구성되어 있습니다. \n",
    "\n",
    "이제 신경망의 입의자료에 대하여 전처리 작업을 마쳤는데, 입력층의 노드의 갯수는 몇개가 되나요? 입력층 노드의 수는 입력자료에 의하여 정해진다고 배웠습니다. 입력층의 노드 수는 28x28 = 784개 되어야 합니다.  아래 그림처럼 말입니다. 복잡하죠? 이것도 일부만 간단히 그린 것이랍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/idebtor/KMOOC-ML/blob/master/ipynb/images/784-128-10NN.png?raw=true\" width=\"500\">\n",
    "<center>그림 3: MNIST 신경망 모델의 구조(1)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: 모델 설계하기\n",
    "\n",
    "인공신경망을 모델을 선정하고, 은닉층의 갯수와 각 층에 사용할 노드의 수 및 활성화 함수를 설정합니다. 학습률과 드롭아웃을 설정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sequential()은 레이어(layer, 층)를 여러 개 차례대로 쌓아서 tf.keras.Sequential 신경망 모델을 생성하여 model이라는 이름으로 저장합니다. 여기서, 우리가 설계한 모델의 입력층 노드는 784개, 은닉층 노드 128개, 출력층 노드 10개로 구성되어 있습니다. Sequential 모델은 입력과 출력이 하나이고, 층 간의 입출력이 반복되는 단순히 연결되어  있는 경우 사용합니다. 입출력이 다양할 경우, 즉 다른 입력을 중간 받는 경우는 새로운 다른 모델을 설계하여 사용하기도 있습니다. 간단한 예로 [여기](https://frhyme.github.io/machine-learning/a_model_in_keras/) 참고하십시오. \n",
    "- Flatten()은 28x28의 배열을 입력으로 받아, 784개의 요소로 구성된 1차원 배열로 변환합니다. \n",
    "- Dense()는 은닉층으로 노드 개수는 128이며, 활성화 함수로 relu로 설정합니다. Relu 활성화 함수는 비선형 함수 중의 하나입니다. Dense층은 선형적인 연산만 하기 때문에 즉 output = dot(W, input) + b 형식으로 입력에 대한 선형적인 변환(affine)만 하기 때문에 Dense 층이 여러 개 구성할지라도 Deep Learning의 장점이 없어집니다. 그러므로, 비선형 활성화 함수를 도입함으로 말미암아 가설 공간에 보다 많은 변형을 가져와 새로운 하이퍼 파라미터 값의 설정 범위가 넓어지게 됩니다. Relu 함수는 가장 많이 사용하는 대표적인 비선형 활성화 함수입니다.   \n",
    "- Dropout()은 오버피팅(overfitting)을 방지하기 위해 무작위로 이전 층의 출력의 노드의 일부를 사용하지 않는 방법인데, 여기에서는 20%를 사용하지 않는 것으로 설정합니다. \n",
    "- Dense()는 출력층으로 노드 개수는 10이며, softwmax를 활성화 함수를 설정합니다. softmax를 사용하면 출력값 간의 편차가 커져서 분류하기 쉽게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 신경망 모델 컴파일 하기\n",
    "\n",
    "이제 사용할 알고리즘 즉 옵티마이저(optimizer)와 손실 함수(loss function), 메트릭(metrics)을 선택합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 옵티마이저(optimizer)와 손실 함수(loss function), 메트릭(metrics)을 선택합니다. \n",
    "- 옵티마이저(최적화 함수)는 손실함수(목적함수)를 기반으로 신경망 모델을 어떻게 갱신할 것인지 결정합니다. 확률적 경사하강법(Stochastic Gradient Descent)을 개선한 알고리즘들(`adam`, `rmsprop`, `adagrad`, 등등)중에 하나인 adam으로 설정합니다. 이에 대한 자세한 설명은 [여기](https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c)를 참조하십시오. 입력된 자료와 손실 함수를 기반으로 신경망의 hyperparameters(가중치, 편향 등등)을 조정하는 메커니즘(알고리즘)의 일종입니다. 예를 들어, 2차원의 손실함수에 경사하강법을 적용한다면, 현재 위치의 기울기를 산출하여 에러가 최소화되는 방향으로 현재 위치를 약간씩 이동하며, 다음 번 학습(epoch)에서 나타나는 오차를 최소화하도록 합니다. \n",
    "- 손실함수는 일종의 목적함수이며, 훈련(학습)하는 동안 최소화될 값입니다. 주어진 문제에 대한 성공 지표가 되며, 이를 최소화하는 방향(목적)으로 학습이 진행됩니다. \n",
    "- 크로스 엔트로피(Cross-Entropy)를 손실 함수(loss function)로 사용합니다. 손실 함수는 학습 자료에서 신경망의 성능을 측정하는 방법으로 신경망이 옳은 방향으로 학습될 수 있도록 도와줍니다. \n",
    "- 모델의 출력이 one-hot encoding되어 있다면, categorical_crossentropy를 사용하고, 모델의 출력이 정수라면 sparse_categorical_crossentropy를 사용합니다. 이진 분류(binary classification)일 때는 binary_crossentropy를 사용합니다.  \n",
    "- 메트릭은 모델을 평가할 때 사용됩니다. 여기에서는 정확도(정확히 분류된 이미지의 비율)만으로 설정하였습니다. \"accuracy\" 혹은 \"acc\"를 일정하게 사용하는 것이 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 신경망 모델 학습 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터셋을 사용하여 모델을 5번 반복하여 훈련시킵니다. 학습 과정은 fit()함수를 통하여 진행하며, fit()함수는 과정중에 발생하는 데이터 이력(history)들을 반환합니다.  전체 훈련 데이터에 대해 연산(훈련)을 한 번 수행하는 것을 에포크(one epoch)라고 부릅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2909 - accuracy: 0.9136\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1422 - accuracy: 0.9574\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1069 - accuracy: 0.9676\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0865 - accuracy: 0.9735\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0745 - accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행할수록 손실(loss)은 작아지고, 정확도(accuracy)는 커지는 것을 관찰할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 신경망 모델 평가 하기\n",
    "\n",
    "학습이 완성되었으니, 이제 테스트 데이터셋을 사용하여 모델을 evaluate()함수로 평가합니다. evaluate()함수는 손실과 정확도를 반환합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/313 [..............................] - ETA: 0s - loss: 0.0721 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "313/313 [==============================] - 0s 918us/step - loss: 0.0790 - accuracy: 0.9739\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)   # loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 학습을 진행했을 때, 모델 자체의 정확도는 98.1로 나왔습니다.테스트셋의 정확도는 97.9이며, 이는 학습 훈련셋의 정확도보다 약간 낮습니다. 그 차이는 과대적합(overfitting)때문입니다. 이는 기계학습 모델이 학습 데이터보다 새로운 데이터에서 성능이 낮아지는 경향을 말합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset 숫자 인식을 위한 코드(tf.keras)\n",
    "지금까지 과정에서 MNIST 데이터셋 숫자 인식을 위한 코드만 간추려 보면 다음과 같이 단 7줄의 코드로 요약될 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2589 - accuracy: 0.9263\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1117 - accuracy: 0.9668\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0771 - accuracy: 0.9767\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.98 - 3s 2ms/step - loss: 0.0580 - accuracy: 0.9822\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0448 - accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0349 - accuracy: 0.9892\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0289 - accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0237 - accuracy: 0.9926\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0188 - accuracy: 0.9944\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0157 - accuracy: 0.9950\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07853339612483978, 0.9765999913215637]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. 분석 과정: Postprocessing\n",
    "\n",
    "학습(훈련) 과정과 테스트 과정을 마친 후, 결과에 대해 좀 더 분석을 원할 때가 많습니다. 이를 위한 다양한 도구와 방법들이 있습니다. \n",
    "\n",
    "- 학습/훈련을 담당하고 있는 fit()함수는 학습 과정 중에 일어나는 손실과 정확도에 대해 저장하여 Dictionary 형식으로 반환합니다\n",
    "- fit()함수를 실행할 때, 검증 자료도 함께 매개 변수로 보내서 검증 자료에 대해서도 손실과 정확도를 측정할 수 있습니다. \n",
    "- evaluate함수도 최종 손실과 정확도를 반환합니다. \n",
    "다음 코드는 이러한 기능들을 추가하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2468 - accuracy: 0.9282\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1113 - accuracy: 0.9668\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0801 - accuracy: 0.9756\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0659 - accuracy: 0.9794\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0533 - accuracy: 0.9831\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0443 - accuracy: 0.9856\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0379 - accuracy: 0.9872\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0336 - accuracy: 0.9890\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0298 - accuracy: 0.9902\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0281 - accuracy: 0.9907\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0258 - accuracy: 0.9912\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0249 - accuracy: 0.9915\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0210 - accuracy: 0.9926\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0208 - accuracy: 0.9929\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0193 - accuracy: 0.9934\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0168 - accuracy: 0.9940\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0166 - accuracy: 0.9940\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0133 - accuracy: 0.9952\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0160 - accuracy: 0.9942\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0152 - accuracy: 0.9949\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0118 - accuracy: 0.9961\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0129 - accuracy: 0.9953\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0129 - accuracy: 0.9957\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0123 - accuracy: 0.9957\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0127 - accuracy: 0.9959\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0131 - accuracy: 0.9955\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0128 - accuracy: 0.9955\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0118 - accuracy: 0.9961\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "print(x_train.shape)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(256, activation='relu'),      #은닉층\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')     #출력층\n",
    "])\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=30)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06967438012361526, 0.9787999987602234]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history의 내부 구조를 알기위해 keys()와 값들을 출력해보면 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.2518015503883362,\n",
       "  0.11550504714250565,\n",
       "  0.08304453641176224,\n",
       "  0.06575553119182587,\n",
       "  0.054073452949523926],\n",
       " 'accuracy': [0.92535001039505,\n",
       "  0.9643166661262512,\n",
       "  0.9739833474159241,\n",
       "  0.9792666435241699,\n",
       "  0.9828166961669922]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 배열마다 열 개의 숫자들로 구성되어 있는데, 이것은 Epoch(반복 회수)에 따라 loss와 accuracy가 저장되어 있다는 것을 관찰할 수 있습니다 이를 시각적으로 관찰하기 위해 그래프로 그려볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "epochs = range(1, 1 + len(loss))            # for x, use len(loss)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, accuracy, 'b', label='Accuracy')\n",
    "plt.title('Training and Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서 볼 수 있듯이 훈련 손실이 epoch마다 감소하고 훈련 정확도는 증가합니다. 경사하강법 최적화를 사용했을 때 반복마다 최소화되는 것이 손실이므로 기대했던 대로입니다.  그러나 검증(validation) 손실과 정확도는 이와 같지 않습니다. 7번째 에포크 이후부터는 그래프의 변화가 거의 없거나 오히려 역전되는 때도 있어 보입니다. 이것이 훈련 데이터셋에서 잘 작동되는 모델이 처음 보는 데이터에서는 잘 작동하지 않을 수 있으며, 이것이 바로 과대적합(overfitting)되었다고 합니다. 어느 정도의 epoch 횟수가 지난 후부터, 훈련 데이터에 과도하게 최적합되어 훈련 데이터셋에 특화된 표현을 학습하므로 훈련 데이터셋이외의 데이터에는 일반화되지 못합니다. \n",
    "\n",
    "이런 경우에 과대적합을 방지하기 위해서 overfitting이 일어나는 이후에 훈련을 중지할 수 있습니다. 과대적합을 피하기위한 다양한 기술들이 있습니다. 일정 비율의 노드(뉴론)을 숨기는 dropout도 이런 기술들 중의 하나입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. 훈련된 모델로 새로운 데이터에 대해 예측하기\n",
    "\n",
    "신경망 모델을 학습시킨 후에 이를 실전 환경에서 사용하길 원할 것입니다. predidt 함수를 사용해서 입력에 대한 숫자를 에측할 수 있습니다. x_test가 새로운 입력이라고 가정한다면, 다음과 같이 실행합니다. yhat은 에측 결과입니다. 형상을 살펴보니 10000개의 예측 결과값들이 있습니다. 각 샘플의 예측값은 10 개의 숫자로 표현되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "yhat shape: (10000, 10)\n",
      "one sample: [6.1061919e-15 1.1735670e-18 2.0572925e-13 1.9599398e-09 3.1325831e-21\n",
      " 6.9080727e-13 1.7421662e-24 1.0000000e+00 1.0657429e-13 4.6540929e-10]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)\n",
    "print(x_test.shape)\n",
    "print('yhat shape:', yhat.shape)\n",
    "print('one sample:', yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 예측 결과를 받았을 때, 관찰을 통하여 하나의 sample `yhat[0]` 입력에 대해 에측 값이 10개의 값으로 구성되어 있는 것을 볼 수 있습니다. 물론, 이 열개의 값을 모두 더하면 1에 가까운 값이 될 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000024263582"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러면, 과연 이 첫번째 샘플 `yhat[0]`에 대하여 모델은 어떤 숫자라고 예측했을까요? 이 열 개의 값들 중에 가장 큰 값이 들어가 있는 배열의 인덱스가 곧 모델이 예측한 값에 해당할 것입니다. 이것을 코딩으로 구현하면 다음과 같습니다. `yhat[0]` 배열에 있는 10개의 요소를 서로 비교하면서, 최대값을 가진 요소의 인덱스를 찾는 코드입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대값의 인덱스: 7\n",
      "레이블 7\n"
     ]
    }
   ],
   "source": [
    "max_value = yhat[0][0]\n",
    "max_index = 0\n",
    "for index, value in enumerate(yhat[0]):\n",
    "    if value > max_value:\n",
    "        max_value = value\n",
    "        max_index = index\n",
    "\n",
    "print('최대값의 인덱스:', max_index)\n",
    "print('레이블', y_test[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "그런데, 파이썬 numpy에는 이와 같은 계산을 해주는 함수 argmax가 이미 존재합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대값의 인덱스: 7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "print('최대값의 인덱스:', np.argmax(yhat[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for loop를 사용하여 10000개 중에 앞에 있는 5개의 샘플에 대해서만 예측한 값을 출력해볼 수 있습니다. 여기서 y_test 레이블이 있다고 가정하고 함께 출력해서 비교해 보았습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] = [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "image=0, predicted=7, label=7\n",
      "[1] = [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "image=1, predicted=2, label=2\n",
      "[2] = [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "image=2, predicted=1, label=1\n",
      "[3] = [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "image=3, predicted=0, label=0\n",
      "[4] = [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "image=4, predicted=4, label=4\n",
      "[321] = [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "image=321, predicted=7, label=2\n",
      "i=321 [0.000e+00 0.000e+00 0.000e+00 1.000e-04 0.000e+00 0.000e+00 0.000e+00\n",
      " 9.999e-01 0.000e+00 0.000e+00]\n"
     ]
    }
   ],
   "source": [
    "for i, iyhat in enumerate(yhat):\n",
    "    if (i < 5 or i == 321):\n",
    "        print('[{}] = {}'.format(i, np.round(iyhat, 3)))\n",
    "        predicted = np.argmax(iyhat)\n",
    "        print('image={}, predicted={}, label={}'.format(i, predicted, y_test[i]))\n",
    "    if i == 321:\n",
    "        print(\"i=321\", np.round(iyhat, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "#### Homework 1: 예측이 틀린 샘플들을 몇 개 있는지 찾아 보십시오.  그래서, 정확도를 계산하십시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.9812\n",
      "[9, 5, 2, 7, 3]\n",
      "[115, 217, 247, 321, 340]\n",
      "[4, 6, 4, 2, 5]\n",
      "[9, 5, 2, 7, 3]\n"
     ]
    }
   ],
   "source": [
    "wrong = []\n",
    "w_idx = []\n",
    "w_lab = []\n",
    "w_pre = []\n",
    "\n",
    "for i, iyhat in enumerate(yhat):\n",
    "    predicted = np.argmax(iyhat)\n",
    "    if predicted != y_test[i]:\n",
    "        wrong.append(predicted)\n",
    "        w_idx.append(i)\n",
    "        w_lab.append(y_test[i])\n",
    "        w_pre.append(predicted)\n",
    "        \n",
    "print(\"accuracy = \", 1 - len(wrong)/len(yhat))\n",
    "print(wrong[:5])\n",
    "print(w_idx[:5])\n",
    "print(w_lab[:5])\n",
    "print(w_pre[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pythonic Coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.9812\n"
     ]
    }
   ],
   "source": [
    "predicted = np.argmax(yhat, axis = 1)\n",
    "print(\"accuracy = \", np.sum(predicted == y_test) / len(yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework 2: 첫 번째로 예측이 틀린 샘플은 무엇이며, 어떤 숫자를 어떻게 인식했는지 찾아내고, 레이블과 함께 시각화하십오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "[(115, 4, 9), (217, 6, 5), (247, 4, 2), (321, 2, 7), (340, 5, 3)]\n",
      "115 4 9\n"
     ]
    }
   ],
   "source": [
    "wrong = []\n",
    "for i, iyhat in enumerate(yhat):\n",
    "    predicted = np.argmax(iyhat)\n",
    "    if predicted != y_test[i]:\n",
    "        wrong.append((i, y_test[i], predicted))\n",
    "\n",
    "print(len(wrong))\n",
    "print(wrong[:5])\n",
    "print(wrong[0][0], wrong[0][1], wrong[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "xstr = \"Sample:\" + str(wrong[0][0]) + \", label:\" + str(wrong[0][1]) + \", predicted:\" + str(wrong[0][2])\n",
    "plt.xlabel(xstr)\n",
    "plt.imshow(x_train[wrong[0][0]], cmap='gray')    # use 'Greys' or cmap=plot.cm.binary for inverted grayscale image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xstr = \"Sample:\" + str(wrong[1][0]) + \", label:\" + str(wrong[1][1]) + \", predicted:\" + str(wrong[1][2])\n",
    "plt.xlabel(xstr)\n",
    "plt.imshow(x_train[wrong[1][0]], cmap='gray')    # use 'Greys' or cmap=plot.cm.binary for inverted grayscale image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xstr = \"Sample:\" + str(wrong[2][0]) + \", label:\" + str(wrong[2][1]) + \", predicted:\" + str(wrong[2][2])\n",
    "plt.xlabel(xstr)\n",
    "plt.imshow(x_train[wrong[2][0]], cmap='gray')    # use 'Greys' or cmap=plot.cm.binary for inverted grayscale image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xstr = \"Sample:\" + str(wrong[3][0]) + \", label:\" + str(wrong[3][1]) + \", predicted:\" + str(wrong[3][2])\n",
    "plt.xlabel(xstr)\n",
    "plt.imshow(x_train[wrong[3][0]], cmap='gray')    # use 'Greys' or cmap=plot.cm.binary for inverted grayscale image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Study\n",
    "\n",
    "## 1. Epoch & batch_size\n",
    "\n",
    "배치 batch 단어의 의미는 `묶음`입니다. batch_size는 신경망 모델을 학습할 때에, 한번에 (한 묶음으로) 모델에 넘겨주는 샘플 데이터의 수를 의미합니다. 예를 들면, 1000개의 입력 데이터셋이 있는데, batch_size = 10으로 넘겨준다고 가정하면, 총 10개씩 batch로서 그룹을 이루어 들어가게 되면, 총100개의 step을 통해서 1 epoch을 학습하는 것입니다. 즉 1 epoch(학습 1회) = 10 (batch_size) * 100 (step or iteration)입니다. Epoch는 전체 데이터를 학습하는 횟수를 의미합니다. 즉, \"1 Epoch = 전체 데이터 학습\"을 의미합니다. 텐서플로의 학습 진행 과정의 출력을 살펴보면, 디폴트로 batch_size=32 설정되어 있다는 것을 관찰할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0660 - accuracy: 0.9793\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0595 - accuracy: 0.9808\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9825\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0480 - accuracy: 0.9839\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0449 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19024be0408>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0306 - accuracy: 0.9902\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0268 - accuracy: 0.9914\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0255 - accuracy: 0.9917\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0235 - accuracy: 0.9921\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0240 - accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19025c7e7c8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0670 - accuracy: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0669904425740242, 0.9814000129699707]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 원 핫 인코딩 one-hot encoding\n",
    "위의 예제에서 y에 저장되어 있는 레이블(label or class)은 각 샘플마다 하나의 수 즉 0~9까지의 정수형 값을 갖고 있습니다. 이러한 형식의 값을 0/1로만 이루어진 벡터로 값을 수정할 수 있습니다. 예를 들면, 레이블이 3이면, `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`로 표현하고, 5이면, `[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]`는 것입니다. 이를 one-hot encoding이라고 합니다. \n",
    "\n",
    "다음 코드는 정수형의 값으로 표현된 레이블 y값을 one-hot encoding으로 변형합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "5\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "y_train_hot = np_utils.to_categorical(y_train, 10)\n",
    "print(y_train.shape)\n",
    "print(y_train_hot.shape)\n",
    "print(y_train[0])\n",
    "print(y_train_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블 y값을 정수형에서 one-hot encoding 형식으로 변형하게 되면, 그에 따라 다른 코드들이 영향을 받습니다. 다음과 같이 compile 함수의 loss 옵션을 수정해야 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2964 - accuracy: 0.9140\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1451 - accuracy: 0.9567\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1096 - accuracy: 0.9667\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0899 - accuracy: 0.9727\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0787 - accuracy: 0.9752\n",
      "313/313 - 0s - loss: 0.0735 - accuracy: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07354003190994263, 0.9764000177383423]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0       # normalization\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)      # one-hot encoding\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='categorical_crossentropy',              # since using one-hot encoding\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델의 저장과 복원\n",
    "\n",
    "tf.keras.Model.save_weights를 사용하여 모델의 가중치를 저장하고 복원합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1900997ed48>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치를 텐서플로의 체크포인트 파일로 저장합니다.\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# 모델의 상태를 복원합니다. 모델의 구조가 동일해야 합니다.\n",
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 모델의 가중치는 텐서플로 체크포인트 파일 포맷으로 저장됩니다. 케라스의 HDF5 포맷으로 가중치를 저장할 수도 있습니다(다양한 백엔드를 지원하는 케라스 구현에서는 HDF5가 기본 설정입니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치를 HDF5 파일로 저장합니다.\n",
    "model.save_weights('my_model.h5', save_format='h5')\n",
    "\n",
    "# 모델의 상태를 복원합니다.\n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 활성화 함수(activation functions)\n",
    "\n",
    "#### ReLU function \n",
    "렐루$^{ReLU}$ 함수는 Rectified Linear Unit의 약자입니다.  렐루 함수는 입력값이 0보다 작으면 0이고 0보다 크면 입력값 그대로를 내보냅니다.  \n",
    "\n",
    "\\begin{align} \n",
    "  h(x) &= \n",
    "  \\begin{cases}\n",
    "   \\ x & \\text{$if \\ x \\ge 0$} \\\\\n",
    "   \\ 0 & \\text{$otherwise$} \\\\ \\tag{8}\n",
    "  \\end{cases}\n",
    "\\end{align}  \n",
    "\n",
    "렐루 함수를 그래프로 나타내면 다음과 같습니다.  `Numpy`의 `maximum`함수를 이용하였는데, 이 함수는 두 입력 중에서 큰 값을 반환합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "x = np.arange(-4.0, 4.0, 0.2)\n",
    "y = relu(x)\n",
    "plt.plot(x, y, label='ReLU')\n",
    "y = np.log(1 + np.exp(x))\n",
    "plt.plot(x, y, label='Softplus')\n",
    "plt.axis('equal')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('h(x)')\n",
    "plt.legend(loc=2)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU 함수의 특징은 다음과 같습니다. \n",
    "- 0 이하의 입력에 대해 0을 출력함으로 부분적으로 활성화 시킬수 있다. \n",
    "- __소멸하는 기울기__$^{vanshing \\ gradient}$ 문제가 없다. \n",
    "- 선형함수이므로 미분 계산이 간단하다.\n",
    "- 입력의 크기에 무관하다$^{scale-invariant}$\n",
    "\n",
    "기계학습에서 많이 사용하던 시그모이드를 렐루가 대체하게 된 이유 중 가장 큰 것이 __소멸하는 기울기__ 문제입니다. 시그모이드 함수는 `0`에서 `1`사이의 값을 가지는데 경사하강법을 사용하여 역전파를 할 때, 은닉층들을 지나면서 기울기$^{gradient}$를 계속 곱하므로 기울기$^{gradient}$는 `0`으로 수렴하게 됩니다. 따라서 은닉층이 많은 딥러닝에서는 잘 작동하지 않게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid function\n",
    "\n",
    "다음은 기계학습에서 가장 많이 사용해왔던 활성화 함수인 시그모이드 함수$^{sigmoid \\ function}$를 나타내는 식입니다. \n",
    "\n",
    "\\begin{align} \n",
    "  sigmoid(x) = \\sigma(x) = \\frac{1}{1 + e^{-x}} \\tag{1} \\\\\n",
    "\\end{align}\n",
    "\n",
    "식(1)에서 $e$는 자연상수로 2.7182...의 값을 갖는 실수입니다.  시그모이드 함수는 복잡한듯 보이지만 사실 상 단순한 함수입니다.  함수는 입력이 주어지면 일정한 방법에 의해 출력을 내주는 것뿐입니다. 예를 들어 시그모이드 함수에 $0$ 입력하면, 즉 $\\sigma(0)$를 하면, 식(4)에서 $x$대신 0를 대입하여 계산 결과 즉 $0.5$를 출력합니다.  $x=0, x=1$경우도 쉽게 계산할 수 있습니다. \n",
    "\\begin{align} \n",
    "  \\sigma(0) &= \\frac{1}{1 + e^{0}} \\\\\n",
    "                &= \\frac{1}{2} \\ \\tag{2} \\\\\n",
    "  \\sigma(1) &= \\frac{1}{1 + e^{-1}} \\\\\n",
    "                &= \\frac{1}{1 + 0.3679...} \\\\\n",
    "                &= 0.731... \\\\\n",
    "  \\sigma(2) &= \\frac{1}{1 + e^{-2}} \\\\\n",
    "                &= \\frac{1}{1 + 0.1353...} \\\\\n",
    "                &= 0.880...\n",
    "\\end{align}\n",
    "\n",
    "시그모이드 함수는 파이썬으로 다음과 같이 작성할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 그러면 이제 시그모이드 함수의 그래프를 그려볼까요? $x$축의 범위를 `-5.0`와 `5.0`사이로 잡고 그에 상응하는 시그모이드 함수 값을 $y$값을 구하여 그래프를 그린 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x,y)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "plt.xlabel('x', fontsize = 16)\n",
    "plt.ylabel('h(x)', fontsize = 16)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.yticks([0.0, 0.5, 1.0])\n",
    "plt.grid(axis='y')\n",
    "plt.title('sigmoid function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드는 가중치`(0.5, 1.0, 2.0)`에 따른 함수의 변화를 살펴본 것입니다.  가중치가 클수록 경사도가 높은 것을 관찰할 수 있습니다.  가중치가 클수록 계단 함수와 비슷해지며, 낮을 수록 완만한 $S$ 곡선을 그리게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5, .1)\n",
    "for w, l in [(0.5, 'w = 0.5'), (1.0, 'w = 1.0'), (2.0, 'w = 2.0')]:\n",
    "    y = sigmoid(x * w)\n",
    "    plt.plot(x, y, label=l)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(loc=2)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "plt.yticks([0.0, 0.5, 1.0])\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수는 그래프에서 관찰할 수 있듯이 S자와 유사한 완만한 시그모이드 커브 형태를 보이는 함수입니다. 이 함수는 모든 실수 입력 값을 0보다 크고 1보다 작은 미분 가능한 수로 변환하는 특징을 갖습니다. 따라서, 우리가 나중에 공부하게 될 로지스틱 분류$^{logistic \\ classification}$ 문제의 가설과 비용 함수$^{cost \\ function}$에 많이 사용됩니다.  또한 함수의 반환 값이 항상 `0`와 `1`사이에 있기 때문에 그 결과를 확률로 해석할 때 유용합니다.  이 함수는 미분 결과가 간결하고 사용하기 쉬우므로 기계학습 초기에 많이 사용되었습니다.  기계학습이나 딥러닝에서 노드가 임계값을 넘을 때만 출력하도록 하는 활성화 함수로 사용하기도 합니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax function\n",
    "Softmax(소프트맥스)는 입력받은 값을 0~1사이의 값으로 출력하도록 모두 정규화하며 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수입니다. 분류하고 싶은 클래수의 수 만큼 출력으로 구성한다. 가장 큰 출력 값을 부여받은 클래스가 확률이 가장 높은 것으로 이용됩니다. 예를 들면, MNIST 데이터셋일 경우, 0 ~ 9까지의 값들 중의 하나로 분류해야 함으로,softmax는 출력은 열 개로 분류하며, 그 중에 가장 높은 확률을 가진 요소가 예측값이 됩니다. \n",
    "\n",
    "소프트맥스를 수식으로 표현하면 다음과 같습니다. \n",
    "\n",
    "\\begin{align} \n",
    "  y_k = \\frac{e^{a_k}}{\\sum_{i=1}^{n}{e^{a_i}}} \n",
    "\\end{align}\n",
    "\n",
    "이를 파이썬으로 구현하면 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def softmax(a) :\n",
    "    return np.exp(a) / np.sum(np.exp(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드는 softmax식을 잘 표현하고 있지만, 컴퓨터로 계산할 때는 오버플로(overflow) 문제가 발생할 수 있다.\n",
    "예를들어, exp(10)은 20,000이 넘고, exp(100)은 0이 40개가 넘는 큰 값이 되고, exp(1000)은 무한대를 뜻하는 inf가 return된다. 그리고 이런 큰 값끼리 나눗셈을 하면 결과가 불안정해진다. 오버플로는 컴퓨터가 표현할 수 있는 수의 범위가 한정되어, 너무 큰 값은 표현할 수 없는 문제입니다. \n",
    "이를 개선하기 위해 softmax 식을 다음과 같이 변형합니다. 분모와 분자에 같은 수 C를 곱하면, 소프트맥스 수식은 다음과 같이 작성할 수 있습니다. \n",
    "\n",
    "\\begin{align} \n",
    "  y_k = \\frac{e^{a_k}}{\\sum_{i=1}^{n}{e^{a_i}}} &= \\frac{C e^{a_k}}{C \\sum_{i=1}^{n}{e^{a_i}}} \\\\\n",
    "  &= \\frac{ e^{a_k + logC} } {\\sum_{i=1}^{n}{e^{a_i + logC}}} \\\\\n",
    "   &= \\frac{ e^{a_k + C'} } {\\sum_{i=1}^{n}{e^{a_i + C'}}} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, softmax지수 함수이므로, 이를 계산할 때 어떤 수를 더하거나 빼도 결과는 바뀌지 않는다는 것입니다. 일반적으로 입력 신호 중 최대값을 빼는방식으로 합니다. \n",
    "\n",
    "예를들면, x에 대한 softmax를 구하는데, 첫번째 코드에서는 연산을 하면 오버플로 현상이 나타나는데, 두번째 코드에서는 입력 신호 x 값들 중에서 최대값을 각 입력값에서 빼는 방식으로 처리하여 결과를 도출할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1010,1000,990])\n",
    "\n",
    "np.exp(x) / np.sum(np.exp(x))\n",
    "np.exp(x - np.max(x))/np.sum(np.exp(x - np.max(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 바탕으로 softmax 함수를 다시 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x) :\n",
    "    ex_c = np.exp(x - np.max(x))\n",
    "    return ex_c / np.sum(ex_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax() 함수를 사용하면 다음과 같이 계산할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02047655 0.15130235 0.8282211 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.8, 2.8, 4.5])\n",
    "y = softmax(x)\n",
    " \n",
    "print(y)\n",
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, softmax 함수의 출력은 0부터 1사이의 실수이며, 출력의 총합은 1입니다. 따라서 이를 \"확률\"로 해석할 수 있습니다. 예를 들어, 위의 예제에서 `y[0]`의 확률은 2%, `y[1]`의 확률은 15%, `y[2]`의 확률은 83%로 해석할 수 있으며, 따라서 input x는 `y[2]` class(혹은 label)에 속한다라고 결론내릴 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "__Be joyful always!__ 1 Thes.5:16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
